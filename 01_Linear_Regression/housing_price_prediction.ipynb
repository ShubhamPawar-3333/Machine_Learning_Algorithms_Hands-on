{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd616641",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "California Housing Price Prediction using Linear Regression\n",
    "===========================================================\n",
    "\n",
    "Real-world application of Linear Regression on California housing data.\n",
    "\n",
    "Dataset: California Housing (sklearn built-in)\n",
    "- 20,640 samples\n",
    "- 8 features (median income, house age, rooms, etc.)\n",
    "- Target: Median house value\n",
    "- Real-world regression problem\n",
    "\n",
    "Author: Machine Learning Hands-on\n",
    "Date: 2025-12-02\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1fade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6fb142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_data():\n",
    "    \"\"\"Load and explore the California housing dataset.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"LOADING CALIFORNIA HOUSING DATASET\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Load data\n",
    "    housing = fetch_california_housing()\n",
    "    df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "    df['MedHouseVal'] = housing.target\n",
    "    \n",
    "    print(f\"\\nDataset Shape: {df.shape}\")\n",
    "    print(f\"\\nFeature Names:\")\n",
    "    for i, name in enumerate(housing.feature_names):\n",
    "        print(f\"  {i+1}. {name}: {housing.feature_names[i]}\")\n",
    "    \n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(f\"\\nDataset Info:\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(f\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum().sum())\n",
    "    \n",
    "    print(f\"\\nStatistical Summary:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    print(f\"\\nTarget Variable (MedHouseVal):\")\n",
    "    print(f\"  Mean: ${df['MedHouseVal'].mean():.2f} (in $100k)\")\n",
    "    print(f\"  Median: ${df['MedHouseVal'].median():.2f}\")\n",
    "    print(f\"  Min: ${df['MedHouseVal'].min():.2f}\")\n",
    "    print(f\"  Max: ${df['MedHouseVal'].max():.2f}\")\n",
    "    \n",
    "    return df, housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5587b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(df):\n",
    "    \"\"\"Visualize dataset characteristics.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"DATA VISUALIZATION\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Target distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    axes[0].hist(df['MedHouseVal'], bins=50, color='skyblue', edgecolor='black')\n",
    "    axes[0].set_xlabel('Median House Value ($100k)')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].set_title('Distribution of House Prices', fontweight='bold')\n",
    "    axes[0].axvline(df['MedHouseVal'].mean(), color='red', linestyle='--', \n",
    "                    linewidth=2, label=f'Mean: ${df[\"MedHouseVal\"].mean():.2f}')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    axes[1].boxplot(df['MedHouseVal'])\n",
    "    axes[1].set_ylabel('Median House Value ($100k)')\n",
    "    axes[1].set_title('Box Plot of House Prices', fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    correlation_matrix = df.corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=1)\n",
    "    plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature correlations with target\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    correlations = df.corr()['MedHouseVal'].drop('MedHouseVal').sort_values()\n",
    "    correlations.plot(kind='barh', color='teal')\n",
    "    plt.xlabel('Correlation with House Price')\n",
    "    plt.title('Feature Correlations with Target', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Scatter plots for top features\n",
    "    top_features = df.corr()['MedHouseVal'].abs().sort_values(ascending=False)[1:5].index\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, feature in enumerate(top_features):\n",
    "        axes[idx].scatter(df[feature], df['MedHouseVal'], alpha=0.3, s=10)\n",
    "        axes[idx].set_xlabel(feature)\n",
    "        axes[idx].set_ylabel('Median House Value')\n",
    "        axes[idx].set_title(f'{feature} vs House Price')\n",
    "        \n",
    "        # Add trend line\n",
    "        z = np.polyfit(df[feature], df['MedHouseVal'], 1)\n",
    "        p = np.poly1d(z)\n",
    "        axes[idx].plot(df[feature], p(df[feature]), \"r--\", linewidth=2, alpha=0.8)\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the dataset.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"DATA PREPROCESSING\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop('MedHouseVal', axis=1)\n",
    "    y = df['MedHouseVal']\n",
    "    \n",
    "    print(f\"\\nFeatures shape: {X.shape}\")\n",
    "    print(f\"Target shape: {y.shape}\")\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline_model(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Train baseline Linear Regression model.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"BASELINE LINEAR REGRESSION\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train model\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = lr.predict(X_train_scaled)\n",
    "    y_pred_test = lr.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    print(f\"\\nTraining R² Score: {train_r2:.4f}\")\n",
    "    print(f\"Test R² Score: {test_r2:.4f}\")\n",
    "    print(f\"\\nTraining RMSE: ${train_rmse:.4f} (in $100k)\")\n",
    "    print(f\"Test RMSE: ${test_rmse:.4f} (in $100k)\")\n",
    "    print(f\"Test MAE: ${test_mae:.4f} (in $100k)\")\n",
    "    \n",
    "    # Coefficients\n",
    "    print(f\"\\nModel Coefficients:\")\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Coefficient': lr.coef_\n",
    "    }).sort_values('Coefficient', key=abs, ascending=False)\n",
    "    print(coef_df.to_string(index=False))\n",
    "    print(f\"\\nIntercept: {lr.intercept_:.4f}\")\n",
    "    \n",
    "    return lr, scaler, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2cc68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ridge_regression(X_train, X_test, y_train, y_test, scaler):\n",
    "    \"\"\"Train Ridge Regression (L2 regularization).\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RIDGE REGRESSION (L2 Regularization)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Try different alpha values\n",
    "    alphas = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    best_alpha = None\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    print(\"\\nTesting different alpha values:\")\n",
    "    for alpha in alphas:\n",
    "        ridge = Ridge(alpha=alpha)\n",
    "        ridge.fit(X_train_scaled, y_train)\n",
    "        score = ridge.score(X_test_scaled, y_test)\n",
    "        print(f\"  Alpha={alpha:6.3f} -> R² = {score:.4f}\")\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_alpha = alpha\n",
    "    \n",
    "    print(f\"\\nBest Alpha: {best_alpha}\")\n",
    "    \n",
    "    # Train with best alpha\n",
    "    ridge = Ridge(alpha=best_alpha)\n",
    "    ridge.fit(X_train_scaled, y_train)\n",
    "    y_pred = ridge.predict(X_test_scaled)\n",
    "    \n",
    "    print(f\"\\nRidge Regression Results:\")\n",
    "    print(f\"R² Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"RMSE: ${np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
    "    print(f\"MAE: ${mean_absolute_error(y_test, y_pred):.4f}\")\n",
    "    \n",
    "    return ridge, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e91e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lasso_regression(X_train, X_test, y_train, y_test, scaler):\n",
    "    \"\"\"Train Lasso Regression (L1 regularization).\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"LASSO REGRESSION (L1 Regularization)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Try different alpha values\n",
    "    alphas = [0.001, 0.01, 0.1, 1, 10]\n",
    "    best_alpha = None\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    print(\"\\nTesting different alpha values:\")\n",
    "    for alpha in alphas:\n",
    "        lasso = Lasso(alpha=alpha, max_iter=10000)\n",
    "        lasso.fit(X_train_scaled, y_train)\n",
    "        score = lasso.score(X_test_scaled, y_test)\n",
    "        n_features_used = np.sum(lasso.coef_ != 0)\n",
    "        print(f\"  Alpha={alpha:6.3f} -> R² = {score:.4f}, Features used: {n_features_used}\")\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_alpha = alpha\n",
    "    \n",
    "    print(f\"\\nBest Alpha: {best_alpha}\")\n",
    "    \n",
    "    # Train with best alpha\n",
    "    lasso = Lasso(alpha=best_alpha, max_iter=10000)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    y_pred = lasso.predict(X_test_scaled)\n",
    "    \n",
    "    print(f\"\\nLasso Regression Results:\")\n",
    "    print(f\"R² Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"RMSE: ${np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
    "    print(f\"MAE: ${mean_absolute_error(y_test, y_pred):.4f}\")\n",
    "    \n",
    "    # Feature selection\n",
    "    print(f\"\\nFeature Selection (non-zero coefficients):\")\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Coefficient': lasso.coef_\n",
    "    })\n",
    "    selected_features = coef_df[coef_df['Coefficient'] != 0].sort_values('Coefficient', key=abs, ascending=False)\n",
    "    print(selected_features.to_string(index=False))\n",
    "    \n",
    "    return lasso, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffd4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_elasticnet(X_train, X_test, y_train, y_test, scaler):\n",
    "    \"\"\"Train ElasticNet (L1 + L2 regularization).\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"ELASTICNET (L1 + L2 Regularization)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train ElasticNet\n",
    "    elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=10000)\n",
    "    elasticnet.fit(X_train_scaled, y_train)\n",
    "    y_pred = elasticnet.predict(X_test_scaled)\n",
    "    \n",
    "    print(f\"\\nElasticNet Results:\")\n",
    "    print(f\"R² Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"RMSE: ${np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
    "    print(f\"MAE: ${mean_absolute_error(y_test, y_pred):.4f}\")\n",
    "    \n",
    "    return elasticnet, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55046ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(y_test, y_pred_lr, y_pred_ridge, y_pred_lasso, y_pred_elastic):\n",
    "    \"\"\"Plot actual vs predicted values for all models.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    models = [\n",
    "        ('Linear Regression', y_pred_lr),\n",
    "        ('Ridge Regression', y_pred_ridge),\n",
    "        ('Lasso Regression', y_pred_lasso),\n",
    "        ('ElasticNet', y_pred_elastic)\n",
    "    ]\n",
    "    \n",
    "    for idx, (name, y_pred) in enumerate(models):\n",
    "        axes[idx].scatter(y_test, y_pred, alpha=0.5, s=20)\n",
    "        axes[idx].plot([y_test.min(), y_test.max()], \n",
    "                      [y_test.min(), y_test.max()], \n",
    "                      'r--', lw=2, label='Perfect Prediction')\n",
    "        axes[idx].set_xlabel('Actual Price ($100k)')\n",
    "        axes[idx].set_ylabel('Predicted Price ($100k)')\n",
    "        axes[idx].set_title(f'{name}\\nR² = {r2_score(y_test, y_pred):.4f}', \n",
    "                           fontweight='bold')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5950fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(y_test, y_pred_lr, y_pred_ridge):\n",
    "    \"\"\"Plot residuals for model diagnostics.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    residuals_lr = y_test - y_pred_lr\n",
    "    residuals_ridge = y_test - y_pred_ridge\n",
    "    \n",
    "    # Residual plot\n",
    "    axes[0].scatter(y_pred_lr, residuals_lr, alpha=0.5, s=20, label='Linear Regression')\n",
    "    axes[0].scatter(y_pred_ridge, residuals_ridge, alpha=0.5, s=20, label='Ridge Regression')\n",
    "    axes[0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "    axes[0].set_xlabel('Predicted Values')\n",
    "    axes[0].set_ylabel('Residuals')\n",
    "    axes[0].set_title('Residual Plot', fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Residual distribution\n",
    "    axes[1].hist(residuals_lr, bins=50, alpha=0.6, label='Linear Regression', color='blue')\n",
    "    axes[1].hist(residuals_ridge, bins=50, alpha=0.6, label='Ridge Regression', color='orange')\n",
    "    axes[1].set_xlabel('Residuals')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].set_title('Residual Distribution', fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cbb651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"CALIFORNIA HOUSING PRICE PREDICTION\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Load and explore\n",
    "    df, housing = load_and_explore_data()\n",
    "    visualize_data(df)\n",
    "    \n",
    "    # Preprocess\n",
    "    X, y = preprocess_data(df)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTraining set: {X_train.shape}\")\n",
    "    print(f\"Test set: {X_test.shape}\")\n",
    "    \n",
    "    # Train models\n",
    "    lr, scaler, y_pred_lr = train_baseline_model(X_train, X_test, y_train, y_test)\n",
    "    ridge, y_pred_ridge = train_ridge_regression(X_train, X_test, y_train, y_test, scaler)\n",
    "    lasso, y_pred_lasso = train_lasso_regression(X_train, X_test, y_train, y_test, scaler)\n",
    "    elasticnet, y_pred_elastic = train_elasticnet(X_train, X_test, y_train, y_test, scaler)\n",
    "    \n",
    "    # Visualizations\n",
    "    plot_predictions(y_test, y_pred_lr, y_pred_ridge, y_pred_lasso, y_pred_elastic)\n",
    "    plot_residuals(y_test, y_pred_lr, y_pred_ridge)\n",
    "    \n",
    "    # Final comparison\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"FINAL MODEL COMPARISON\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Model': ['Linear Regression', 'Ridge', 'Lasso', 'ElasticNet'],\n",
    "        'R² Score': [\n",
    "            r2_score(y_test, y_pred_lr),\n",
    "            r2_score(y_test, y_pred_ridge),\n",
    "            r2_score(y_test, y_pred_lasso),\n",
    "            r2_score(y_test, y_pred_elastic)\n",
    "        ],\n",
    "        'RMSE': [\n",
    "            np.sqrt(mean_squared_error(y_test, y_pred_lr)),\n",
    "            np.sqrt(mean_squared_error(y_test, y_pred_ridge)),\n",
    "            np.sqrt(mean_squared_error(y_test, y_pred_lasso)),\n",
    "            np.sqrt(mean_squared_error(y_test, y_pred_elastic))\n",
    "        ],\n",
    "        'MAE': [\n",
    "            mean_absolute_error(y_test, y_pred_lr),\n",
    "            mean_absolute_error(y_test, y_pred_ridge),\n",
    "            mean_absolute_error(y_test, y_pred_lasso),\n",
    "            mean_absolute_error(y_test, y_pred_elastic)\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    print(\"\\n\", results.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"✅ HOUSING PRICE PREDICTION PROJECT COMPLETE!\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nKey Learnings:\")\n",
    "    print(\"1. Linear Regression provides baseline performance\")\n",
    "    print(\"2. Ridge helps with multicollinearity\")\n",
    "    print(\"3. Lasso performs feature selection\")\n",
    "    print(\"4. ElasticNet combines benefits of Ridge and Lasso\")\n",
    "    print(\"5. Regularization prevents overfitting\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
